# Real-time Malaysia Reddit Term Extraction Analysis
This project focuses on term extraction analysis from the Malaysia Reddit dataset using a variety of Natural Language Processing (NLP) tools. The project employs ETL/ELT processes and advanced text analytics techniques to identify significant terms, trends, and patterns within the text corpus. Key tools like NLTK, GoogleTrans, Jieba, SpaCy, and Contractions were leveraged for language processing and word lemmatization.

## Key Features
* ETL/ELT Pipeline: Implemented ETL/ELT steps using tools like PRAW, Kafka, and PySpark to collect, process, and load Reddit data.
* NLP Toolset: Utilized NLTK for text analytics, GoogleTrans for language detection and translation, Jieba for Chinese segmentation, and SpaCy for Malay word lemmatization.
* Term Extraction Techniques: Applied techniques such as TextRank, Yake, Keybert, and Rake NLTK to extract important terms and keywords.
* N-gram Analysis: Generated unigrams, bigrams, and trigrams for deeper insights into term frequency and co-occurrence.

## Technologies Used
* Python
* PRAW (for Reddit data extraction)
* Kafka, PySpark (for ETL/ELT)
* HBase, MongoDB (for data storage)
* NLTK, SpaCy, Jieba, GoogleTrans, Contractions, Demoji (for text processing)
* TextRank, Yake, Keybert, Rake NLTK (for term extraction)

## Project Impact
This project showcases the potential of NLP and term extraction in analyzing large-scale text datasets. By applying advanced techniques such as TextRank, Yake, and N-gram analysis, it provides valuable insights into trends and significant terms from the Malaysia Reddit corpus.
